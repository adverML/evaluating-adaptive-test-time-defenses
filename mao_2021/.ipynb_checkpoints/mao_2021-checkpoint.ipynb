{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEDG-IdgrRBb"
   },
   "source": [
    "# Adversarial Attacks are Reversible via Natural Supervision\n",
    "\n",
    "Evaluation of _Adversarial Attacks are Reversible via Natural Supervision_.\n",
    "\n",
    "To run this on a local runtime:\n",
    "```\n",
    "pip install jupyter_http_over_ws\n",
    "jupyter serverextension enable --py jupyter_http_over_ws\n",
    "pip install ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter notebook \\\n",
    "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
    "  --port=8888 \\\n",
    "  --NotebookApp.port_retries=0\n",
    "# Install python packages as you see fit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7pRRFtnrPJu"
   },
   "source": [
    "## Setup (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmsZ9bJ0FDdD"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/fra31/auto-attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZYigYr2FK2u"
   },
   "outputs": [],
   "source": [
    "!wget https://cv.cs.columbia.edu/mcz/ICCVRevAttack/cifar10_rst_adv.pt.ckpt\n",
    "!wget https://cv.cs.columbia.edu/mcz/ICCVRevAttack/ssl_model_130.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5MgsadjGF8o"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cvlab-columbia/SelfSupDefense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfzY2CQdrNc-"
   },
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BG0qxwA3GVuU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'SelfSupDefense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cl7PtpMrFYEF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from learning.unlabel_WRN import WideResNet_2\n",
    "from learning.wideresnet import WRN34_out_branch\n",
    "from utils import *\n",
    "\n",
    "core_model = WideResNet_2(depth=28, widen_factor=10)\n",
    "contrastive_head_model = WRN34_out_branch()\n",
    "\n",
    "tmp = torch.load('cifar10_rst_adv.pt.ckpt', map_location=device)['state_dict']\n",
    "new_tmp = {k[len('module.'):]: v for k, v in tmp.items()}\n",
    "core_model.load_state_dict(new_tmp)\n",
    "\n",
    "tmp = torch.load('ssl_model_130.pth', map_location=device)['ssl_model']\n",
    "new_tmp = {k[len('module.'):]: v for k, v in tmp.items()}\n",
    "contrastive_head_model.load_state_dict(new_tmp)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  core_model = core_model.cuda()\n",
    "  contrastive_head_model = contrastive_head_model.cuda()\n",
    "core_model.eval()\n",
    "contrastive_head_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2KnXuNHtHDb"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "SAynT5HAVlYB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dir = './data'  #@param {type: 'string'}\n",
    "batch_size = 50  #@param {type: 'integer'}\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "\n",
    "class Batches():\n",
    "  def __init__(self, dataset, batch_size, shuffle, set_random_choices=False, num_workers=0, drop_last=False):\n",
    "    self.dataset = dataset\n",
    "    self.batch_size = batch_size\n",
    "    self.set_random_choices = set_random_choices\n",
    "    self.dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "  def __iter__(self):\n",
    "    if self.set_random_choices:\n",
    "        self.dataset.set_random_choices()\n",
    "    return ({'input': x.to(device).float(), 'target': y.to(device).long()} for (x,y) in self.dataloader)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataloader)\n",
    "\n",
    "\n",
    "transforms = [Crop(32, 32), FlipLR()]\n",
    "dataset = cifar10(data_dir)\n",
    "train_set = list(zip(transpose(pad(dataset['train']['data'], 4) / 255.), dataset['train']['labels']))\n",
    "train_set_x = Transform(train_set, transforms)\n",
    "train_batches = Batches(train_set_x, batch_size, shuffle=True, set_random_choices=True, num_workers=2)\n",
    "test_set = list(zip(transpose(dataset['test']['data'] / 255.), dataset['test']['labels']))\n",
    "test_batches = Batches(test_set, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5a5MdXvrkoB"
   },
   "source": [
    "## Define constrastive loss and full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rih2gSxG-Ne"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "t = torch.nn.Sequential(\n",
    "    transforms.RandomResizedCrop(size=32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "    transforms.RandomGrayscale(p=0.2))\n",
    "\n",
    "scripted_transforms = torch.jit.script(t)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def _contrastive_loss(embeddings, batch_size, num_views):\n",
    "  features = F.normalize(embeddings, dim=1)\n",
    "  labels = torch.cat([torch.arange(batch_size) for i in range(num_views)], dim=0)\n",
    "  labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "  labels = labels.cuda()\n",
    "  similarity_matrix = torch.matmul(features, features.T)\n",
    "  mask = torch.eye(labels.shape[0], dtype=torch.bool).cuda()\n",
    "  labels = labels[~mask].view(labels.shape[0], -1)\n",
    "  similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "  positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "  negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "  logits = torch.cat([positives, negatives], dim=1)\n",
    "  labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "  temperature = 0.2\n",
    "  logits = logits / temperature\n",
    "  xcontrast_loss = criterion(logits, labels)\n",
    "  correct = (logits.max(1)[1] == labels).sum().item()\n",
    "  return xcontrast_loss, correct\n",
    "\n",
    "\n",
    "def contrastive_loss(x, num_views=2, deterministic=False):\n",
    "  # Make things deterministic.\n",
    "  if deterministic:\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "  assert num_views in (2, 4)\n",
    "  xs_transformed = []\n",
    "  # First 2 views.\n",
    "  xs_transformed.append(scripted_transforms(x))\n",
    "  xs_transformed.append(scripted_transforms(x))\n",
    "  if num_views == 4:\n",
    "    xs_transformed.append(scripted_transforms(x))\n",
    "    xs_transformed.append(scripted_transforms(x))\n",
    "  x_constrastive = torch.cat(xs_transformed, dim=0)\n",
    "  _, out = core_model(x_constrastive)\n",
    "  embeddings = contrastive_head_model(out)\n",
    "  closs, acc = _contrastive_loss(embeddings, x.size(0), num_views)\n",
    "  return closs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V4wfUIzH5lL"
   },
   "outputs": [],
   "source": [
    "# Original code runs this once (due to a bug in PyTorch ?!).\n",
    "# for i, batch in enumerate(train_batches):\n",
    "#   x = batch['input']\n",
    "#   _ = contrastive_loss(x)\n",
    "#   break\n",
    "\n",
    "# This is the original implementation (not clear why not use torch.clamp).\n",
    "# def clamp(X, lower_limit, upper_limit):\n",
    "#   return torch.max(torch.min(X, upper_limit), lower_limit)\n",
    "  \n",
    "\n",
    "def repair_inputs(inputs, epsilon=16/255, alpha=2/255, num_steps=40, num_views=2, deterministic=False):\n",
    "  with torch.enable_grad():\n",
    "    delta = torch.zeros_like(inputs).cuda()\n",
    "    # The original resamples delta randomly.\n",
    "    # delta.uniform_(-epsilon, epsilon)\n",
    "    # delta = clamp(delta, -inputs, 1-inputs)\n",
    "    delta.requires_grad_()\n",
    "    for _ in range(num_steps):\n",
    "      new_x = inputs + delta\n",
    "      loss = -contrastive_loss(new_x, num_views=num_views, deterministic=deterministic)\n",
    "      grad = torch.autograd.grad(loss, delta, retain_graph=True, create_graph=False)[0]\n",
    "      delta = delta + alpha * torch.sign(grad)\n",
    "      delta = torch.clamp(delta, min=-epsilon, max=epsilon)\n",
    "      delta = torch.clamp(inputs + delta, min=0, max=1) - inputs\n",
    "      # Original code below. The above code should do the same but allow for AutoAttack to work.\n",
    "      # loss.backward()\n",
    "      # grad = delta.grad.detach()\n",
    "      # delta.data = clamp(torch.clamp(delta + alpha * torch.sign(grad), min=-epsilon, max=epsilon), -inputs, 1-inputs)\n",
    "      # delta.grad.zero_()\n",
    "  return delta.detach() + inputs\n",
    "\n",
    "\n",
    "def defended_model(x, epsilon=16/255, alpha=2/255, num_steps=40, num_views=2, deterministic=False):\n",
    "  rep_x = repair_inputs(x, epsilon=epsilon, alpha=alpha, num_steps=num_steps, num_views=num_views, deterministic=deterministic)\n",
    "  output, _ = core_model(rep_x)\n",
    "  return output\n",
    "\n",
    "\n",
    "def defended_model_bpda(x, epsilon=16/255, alpha=2/255, num_steps=40, num_views=2, deterministic=False):\n",
    "    z = x.clone().detach()\n",
    "    with torch.no_grad():\n",
    "        delta = repair_inputs(x, epsilon=epsilon, alpha=alpha, num_steps=num_steps, num_views=num_views, deterministic=deterministic) - z\n",
    "    output, _ = core_model(x + delta)\n",
    "    return output\n",
    "\n",
    "\n",
    "def undefended_model(x):\n",
    "  output, _ = core_model(x)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZXbPPIuppzp"
   },
   "source": [
    "## Evaluation (of Semi-SL model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErZPoyvGwZoL"
   },
   "outputs": [],
   "source": [
    "# Clean accuracy\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "t = time.time()\n",
    "total_correct = 0.\n",
    "total_count = 0\n",
    "for i, batch in tqdm(enumerate(test_batches)):\n",
    "  x, y = batch['input'], batch['target']\n",
    "  output = undefended_model(x)\n",
    "  total_correct += (output.max(1)[1] == y).sum().item()\n",
    "  total_count += y.size(0)\n",
    "  torch.cuda.empty_cache()\n",
    "  if i == 5:\n",
    "    break\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'Accuracy: {100.*total_correct/total_count:.2f}%')\n",
    "print(f'Time: {t}[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3wqQuTEwFBE"
   },
   "outputs": [],
   "source": [
    "from autoattack import AutoAttack\n",
    "\n",
    "base_adversary = AutoAttack(undefended_model, norm='Linf', eps=8. / 255, verbose=True)\n",
    "base_adversary.attacks_to_run = ['apgd-ce', 'apgd-dlr']\n",
    "base_adversary.apgd.n_restarts = 1\n",
    "base_adversary.apgd.n_iter = 10\n",
    "\n",
    "# Base model.\n",
    "total_correct = 0.\n",
    "total_count = 0\n",
    "for i, batch in tqdm(enumerate(test_batches)):\n",
    "  x, y = batch['input'], batch['target']\n",
    "  adv_autoattack, adv_labels = base_adversary.run_standard_evaluation(x, y, bs=x.shape[0], return_labels=True)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71W6iBGxzEut"
   },
   "source": [
    "## SelfSup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ1JeghqzD-L"
   },
   "outputs": [],
   "source": [
    "# Clean accuracy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "t = time.time()\n",
    "total_correct = 0.\n",
    "total_count = 0\n",
    "for i, batch in tqdm(enumerate(test_batches)):\n",
    "  x, y = batch['input'], batch['target']\n",
    "  output = defended_model(x, epsilon=16/255, alpha=8/255, num_steps=2, num_views=2)\n",
    "  total_correct += (output.max(1)[1] == y).sum().item()\n",
    "  total_count += y.size(0)\n",
    "  torch.cuda.empty_cache()\n",
    "  if i == 5:\n",
    "    break\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'Accuracy: {100.*total_correct/total_count:.2f}%')\n",
    "print(f'Time: {t}[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWB5gBhtQsaC"
   },
   "outputs": [],
   "source": [
    "# Transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8qHRf6py5ZP"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from autoattack import AutoAttack\n",
    "\n",
    "attack_num_steps = 10\n",
    "attack_epsilon = 8/255\n",
    "\n",
    "defense_epsilon = 16/255\n",
    "defense_alpha = 2/255\n",
    "defense_num_steps = 10\n",
    "defense_num_views = 2\n",
    "\n",
    "base_adversary = AutoAttack(undefended_model, norm='Linf', eps=attack_epsilon, verbose=False)\n",
    "base_adversary.attacks_to_run = ['apgd-ce', 'apgd-dlr']\n",
    "base_adversary.apgd.n_restarts = 1\n",
    "base_adversary.apgd.n_iter = attack_num_steps\n",
    "\n",
    "deterministic_adversary = AutoAttack(functools.partial(defended_model_bpda, epsilon=defense_epsilon, alpha=defense_alpha, num_steps=defense_num_steps, num_views=defense_num_views, deterministic=True), norm='Linf', eps=attack_epsilon, verbose=False)\n",
    "deterministic_adversary.attacks_to_run = ['apgd-ce', 'apgd-dlr']\n",
    "deterministic_adversary.apgd.n_restarts = 1\n",
    "deterministic_adversary.apgd.n_iter = attack_num_steps\n",
    "\n",
    "random_adversary = AutoAttack(functools.partial(defended_model_bpda, epsilon=defense_epsilon, alpha=defense_alpha, num_steps=defense_num_steps, num_views=defense_num_views, deterministic=False), norm='Linf', eps=attack_epsilon, verbose=False)\n",
    "random_adversary.attacks_to_run = ['apgd-ce', 'apgd-dlr']\n",
    "random_adversary.apgd.n_restarts = 1\n",
    "random_adversary.apgd.n_iter = attack_num_steps\n",
    "random_adversary.apgd.eot_iter = 20\n",
    "\n",
    "# Wrapped model.\n",
    "clean_total_correct = 0\n",
    "base_total_correct = 0\n",
    "transfer_total_correct = 0\n",
    "deterministic_total_correct = 0\n",
    "random_total_correct = 0\n",
    "total_count = 0\n",
    "num_examples = 1000\n",
    "\n",
    "for i, batch in tqdm(enumerate(test_batches)):\n",
    "  x, y = batch['input'], batch['target']\n",
    "  total_count += y.size(0)\n",
    "\n",
    "  # Clean performance.\n",
    "  output = defended_model(x, epsilon=defense_epsilon, alpha=defense_alpha, num_steps=defense_num_steps, num_views=defense_num_views)\n",
    "  clean_total_correct += (output.max(1)[1] == y).sum().item()\n",
    "\n",
    "  # Base model.\n",
    "  adv_autoattack, adv_labels = base_adversary.run_standard_evaluation(x, y, bs=y.size(0), return_labels=True)\n",
    "  base_total_correct += (adv_labels == y).sum().item()\n",
    "\n",
    "  # Transfer.\n",
    "  output = defended_model(adv_autoattack, epsilon=defense_epsilon, alpha=defense_alpha, num_steps=defense_num_steps, num_views=defense_num_views)\n",
    "  transfer_total_correct += (output.max(1)[1] == y).sum().item()\n",
    "\n",
    "  # Deterministic model.\n",
    "  _, adv_labels = deterministic_adversary.run_standard_evaluation(x, y, bs=y.size(0), return_labels=True)\n",
    "  deterministic_total_correct += (adv_labels == y).sum().item()\n",
    "\n",
    "  # Random model.\n",
    "  _, adv_labels = random_adversary.run_standard_evaluation(x, y, bs=y.size(0), return_labels=True)\n",
    "  random_total_correct += (adv_labels == y).sum().item()\n",
    "\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  print(f\"\\n\\nClean accuracy: {100.*clean_total_correct/total_count:.2f}%\")\n",
    "  print(f\"Robust accuracy (base): {100.*base_total_correct/total_count:.2f}%\")\n",
    "  print(f\"Robust accuracy (transfer): {100.*transfer_total_correct/total_count:.2f}%\")\n",
    "  print(f\"Robust accuracy (full, deterministic): {100.*deterministic_total_correct/total_count:.2f}%\")\n",
    "  print(f\"Robust accuracy (full, random): {100.*random_total_correct/total_count:.2f}%\")\n",
    "\n",
    "  if total_count >= num_examples:\n",
    "    break\n",
    "\n",
    "print(\"\\n\\nFINAL:\")\n",
    "print(f\"Clean accuracy: {100.*clean_total_correct/total_count:.2f}%\")\n",
    "print(f\"Robust accuracy (base): {100.*base_total_correct/total_count:.2f}%\")\n",
    "print(f\"Robust accuracy (transfer): {100.*transfer_total_correct/total_count:.2f}%\")\n",
    "print(f\"Robust accuracy (full, deterministic): {100.*deterministic_total_correct/total_count:.2f}%\")\n",
    "print(f\"Robust accuracy (full, random): {100.*random_total_correct/total_count:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNU9PdmtgZkn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "D7pRRFtnrPJu",
    "UfzY2CQdrNc-",
    "y2KnXuNHtHDb"
   ],
   "name": "mao_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
