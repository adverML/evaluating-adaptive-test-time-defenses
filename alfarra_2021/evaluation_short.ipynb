{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anti-Adversaries: Evaluated against RayS",
      "provenance": [],
      "collapsed_sections": [
        "I_plVqILEtFA",
        "zvJBSBefE-XN",
        "2q0r43MWF4kL",
        "UN4NturaAWAW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75a326f02321428891e1dc4f159a5010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7b4dde72ad549f3a7f65d4179326038",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca1460ab7576419e9edb5d5542af298d",
              "IPY_MODEL_9f94ca0517bf4237aeef6bb613ddc211",
              "IPY_MODEL_0767bf74f6be43308fe0358825a113ba"
            ]
          }
        },
        "d7b4dde72ad549f3a7f65d4179326038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca1460ab7576419e9edb5d5542af298d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c060a79964ca4e76881102009a2138b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53d126607f0f4e7693710cadfcd482cd"
          }
        },
        "9f94ca0517bf4237aeef6bb613ddc211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_272fde79b3674c78a882ad2a943b2f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8748df009b34d10ab47e184c8283efc"
          }
        },
        "0767bf74f6be43308fe0358825a113ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cc33d3835804d94bb9afb4edc5b2534",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:12&lt;00:00, 13916836.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9733a96ed3f4a0aa9f6f9863d4b80ca"
          }
        },
        "c060a79964ca4e76881102009a2138b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53d126607f0f4e7693710cadfcd482cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "272fde79b3674c78a882ad2a943b2f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8748df009b34d10ab47e184c8283efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cc33d3835804d94bb9afb4edc5b2534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9733a96ed3f4a0aa9f6f9863d4b80ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2C1bQtBTYM9"
      },
      "source": [
        "# Evaluating \"Combating Adversaries with Anti-Adversaries\"\n",
        "\n",
        "Note on runtime: To stay within the free colab limits, this colab evaluates only 100 imgs for 1k RayS queries each. Takes ~3h (using a K80 GPU). More will probably time out.\n",
        "\n",
        "In order to reproduce the full evaluation (1000 imgs for 10k queries), run the colab with a faster GPU and/or custom runtime.\n",
        "\n",
        "Paper: https://arxiv.org/pdf/2103.14347.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_plVqILEtFA"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkANloZLL-fa",
        "outputId": "09429db1-82c6-4201-9372-41ea68868097"
      },
      "source": [
        "# Clone repo and install some dependencies\n",
        "!git clone https://github.com/MotasemAlfarra/Combating-Adversaries-with-Anti-Adversaries\n",
        "!git clone https://github.com/uclaml/RayS\n",
        "!sed -i \"s/_, term_width = os.popen('stty size', 'r').read().split()/term_width=80/g\" RayS/pgbar.py     # Fix terminal width in pgbar code\n",
        "!pip install git+https://github.com/fra31/auto-attack\n",
        "import sys\n",
        "sys.path.insert(0,'Combating-Adversaries-with-Anti-Adversaries')\n",
        "sys.path.insert(0,'RayS')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Combating-Adversaries-with-Anti-Adversaries'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 74 (delta 36), reused 12 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n",
            "Cloning into 'RayS'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 123 (delta 68), reused 80 (delta 31), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (123/123), 5.62 MiB | 4.61 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "Collecting git+https://github.com/fra31/auto-attack\n",
            "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-hno0st4g\n",
            "  Running command git clone -q https://github.com/fra31/auto-attack /tmp/pip-req-build-hno0st4g\n",
            "Building wheels for collected packages: autoattack\n",
            "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autoattack: filename=autoattack-0.1-py3-none-any.whl size=34495 sha256=64f50100bb33c1ff9b2afef00e8536d984876dbfd21098e8eb69cdf460f2d103\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k8n9i2la/wheels/a2/71/8b/ec4bb51ceac509961546bf5430b7cf433f93bd375ffa75ea45\n",
            "Successfully built autoattack\n",
            "Installing collected packages: autoattack\n",
            "Successfully installed autoattack-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJMiyl3H9DfF"
      },
      "source": [
        "# Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh-fzbkQ9CK4"
      },
      "source": [
        "eps_linf = 0.031         # Almost 8/255. This is the exact value as used in the defense reference implementation\n",
        "n_imgs = 100             # Don't eval more than n images\n",
        "batch_size = 100\n",
        "batch_size = min(batch_size, n_imgs)\n",
        "\n",
        "rays_n_queries = 1000"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvJBSBefE-XN"
      },
      "source": [
        "# Get CIFAR10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o5lIvHJPoy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "75a326f02321428891e1dc4f159a5010",
            "d7b4dde72ad549f3a7f65d4179326038",
            "ca1460ab7576419e9edb5d5542af298d",
            "9f94ca0517bf4237aeef6bb613ddc211",
            "0767bf74f6be43308fe0358825a113ba",
            "c060a79964ca4e76881102009a2138b4",
            "53d126607f0f4e7693710cadfcd482cd",
            "272fde79b3674c78a882ad2a943b2f68",
            "d8748df009b34d10ab47e184c8283efc",
            "1cc33d3835804d94bb9afb4edc5b2534",
            "f9733a96ed3f4a0aa9f6f9863d4b80ca"
          ]
        },
        "outputId": "36ba313a-47dc-4269-b5c2-dd07aa96da90"
      },
      "source": [
        "# Get CIFAR10 dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     ])     # The model already contains the preprocessing\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=1)\n",
        "\n",
        "# Move everything into memory\n",
        "x_test_clean = torch.cat([x for (x, y) in testloader], 0).to(\"cuda\")[:n_imgs]\n",
        "y_test = torch.cat([y for (x, y) in testloader], 0).to(\"cuda\")[:n_imgs]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a326f02321428891e1dc4f159a5010",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q0r43MWF4kL"
      },
      "source": [
        "# Setup the pretrained AWP classifier\n",
        "\n",
        "Using the same model as in the reference implementation at https://github.com/MotasemAlfarra/Combating-Adversaries-with-Anti-Adversaries. This model is adversarially-trained with Adversarial Weight Perturbation, so it is already quite robust. The defense (Anti-Adversaries) is included as preprocessing step and claims to further increase robustness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1dpqyZkiPXV",
        "outputId": "179bfce0-6180-4cef-add6-b5d5184733d3"
      },
      "source": [
        "# Get pretrained AWP model, same as used in the reference implementation\n",
        "!gdown --id 1sSjh4i2imdoprw_JcPj2cZzrJm0RIRI6\n",
        "!mkdir weights\n",
        "!mv RST-AWP_cifar10_linf_wrn28-10.pt weights/newmodel1_RST-AWP_cifar10_linf_wrn28-10.pt\n",
        "from experiments.adv_weight_pert import get_model as get_awp_model\n",
        "model_undefended = get_awp_model(k=0, alpha=0).eval().to(\"cuda\")\n",
        "model_defended = get_awp_model(k=2, alpha=0.15).eval().to(\"cuda\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sSjh4i2imdoprw_JcPj2cZzrJm0RIRI6\n",
            "To: /content/RST-AWP_cifar10_linf_wrn28-10.pt\n",
            "100% 153M/153M [00:01<00:00, 83.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf1lRD0jnDSt"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "def eval_acc(model, x, y_gt):\n",
        "  assert x.shape[0] == y_gt.shape[0]\n",
        "  n = x.shape[0]\n",
        "  \n",
        "  n_batches = n // batch_size\n",
        "  if n % batch_size != 0:\n",
        "    n_batches += 1\n",
        "\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for i_batch in tqdm.tqdm(range(n_batches)):    \n",
        "          excerpt = slice(i_batch * batch_size, (i_batch+1) * batch_size)\n",
        "          outputs = model(x[excerpt])\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          correct += (predicted == y_gt[excerpt]).sum().item()\n",
        "  return correct / n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2-VTuYGG0vv"
      },
      "source": [
        "# Clean accuracy\n",
        "\n",
        "Both undefended and defended models have similar accuracy. This is in line with the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Qibv4yoxYa",
        "outputId": "eb8b448b-83e0-48a3-f9b0-f9e1e3b2439d"
      },
      "source": [
        "print(f\"Undefended model accuracy on clean imgs: {eval_acc(model_undefended, x=x_test_clean, y_gt=y_test)}\")\n",
        "print(f\"Defended model accuracy on clean imgs: {eval_acc(model_defended, x=x_test_clean, y_gt=y_test)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undefended model accuracy on clean imgs: 0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defended model accuracy on clean imgs: 0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSn8-ZICmdSL"
      },
      "source": [
        "# Reproducing paper claims with AutoAttack\n",
        "\n",
        "Only running APGD-CE for brevity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK1LDcaZz9tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c25eba-4739-486e-e367-e3689cdcdad8"
      },
      "source": [
        "from autoattack import AutoAttack\n",
        "print(\"AutoAttack on undefended model:\")\n",
        "adversary = AutoAttack(model_undefended.forward, norm='Linf', eps=eps_linf, verbose=True)\n",
        "adversary.attacks_to_run = ['apgd-ce']\n",
        "adv_autoattack_undefended = adversary.run_standard_evaluation_individual(x_orig=x_test_clean, y_orig=y_test, bs=batch_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoAttack on undefended model:\n",
            "setting parameters for standard version\n",
            "using standard version including apgd-ce\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autoattack/checks.py\", line 100, in check_dynamic\n",
            "    sys.settrace(tracefunc)\n",
            "\n",
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autoattack/checks.py\", line 102, in check_dynamic\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "robust accuracy by APGD-CE \t 62.00% \t (time attack: 45.0 s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbeafkzLq1JT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48896f5a-a0cc-4568-e2ff-f1078fec7db2"
      },
      "source": [
        "print(\"AutoAttack on defended model:\")\n",
        "adversary = AutoAttack(model_defended.forward, norm='Linf', eps=eps_linf, verbose=True)\n",
        "adversary.attacks_to_run = ['apgd-ce']\n",
        "adv_autoattack_defended = adversary.run_standard_evaluation_individual(x_orig=x_test_clean, y_orig=y_test, bs=batch_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoAttack on defended model:\n",
            "setting parameters for standard version\n",
            "using standard version including apgd-ce\n",
            "Warning: it seems to be a randomized defense! Please use version=\"rand\". See flags_doc.md for details.\n",
            "Warning: it seems to be a dynamic defense! The evaluation with AutoAttack might be insufficient. See flags_doc.md for details.\n",
            "robust accuracy by APGD-CE \t 81.00% \t (time attack: 174.7 s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwyCZhiAulGS"
      },
      "source": [
        "The results are similar to the paper: The defense increases robustness against APGD-CE when directly attacked."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A trivial transfer attack\n",
        "\n",
        "The defense is easily circumvented by transferring adversarial examples from the underlying model:"
      ],
      "metadata": {
        "id": "1wFO8O2q1RTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_adv = adv_autoattack_undefended['apgd-ce']\n",
        "print(f\"Undefended model accuracy on adv. examples created for undefended model: {eval_acc(model_undefended, x=x_test_adv, y_gt=y_test)}\")\n",
        "print(f\"Defended model accuracy on adv. examples created for undefended model: {eval_acc(model_defended, x=x_test_adv, y_gt=y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFgcDEcyHl6d",
        "outputId": "799d52d7-6b24-4fe8-bfbc-e83e51b703f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undefended model accuracy on adv. examples created for undefended model: 0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defended model accuracy on adv. examples created for undefended model: 0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4Zwo7vTm0sy"
      },
      "source": [
        "# Decision-based attack with RayS\n",
        "\n",
        "However, it is also possible to successfully attack the defense without any knowledge of the underlying classifier:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN4NturaAWAW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLtQo2HZ2uhG"
      },
      "source": [
        "from general_torch_model import GeneralTorchModel\n",
        "from RayS import RayS\n",
        "\n",
        "def run_rays_attack(model, n_queries):\n",
        "  print(f\"Running RayS attack with {n_queries} queries. This could take a while...\")\n",
        "  rays_torch_model = GeneralTorchModel(model, n_class=10, im_mean=None, im_std=None)\n",
        "  attack = RayS(rays_torch_model, epsilon=eps_linf)\n",
        "\n",
        "  n_batches = x_test_clean.shape[0] // batch_size\n",
        "  if x_test_clean.shape[0] % batch_size != 0:\n",
        "    n_batches += 1\n",
        "\n",
        "  n_total = 0\n",
        "  n_robust_correct = 0\n",
        "\n",
        "  progress_bar = tqdm.tqdm(range(n_batches))\n",
        "  for i_batch in progress_bar:    \n",
        "      excerpt = slice(i_batch * batch_size, (i_batch+1) * batch_size)\n",
        "      x_batch_clean = x_test_clean[excerpt]\n",
        "      y_batch_gt = y_test[excerpt]\n",
        "\n",
        "      x_batch_adv, queries, adbd, succ = attack(data=x_batch_clean, label=y_batch_gt, query_limit=n_queries)\n",
        "      #print(f\"This batch: attack reports success rate of {torch.sum(succ).item() / x_batch_clean.shape[0]}\")\n",
        "\n",
        "      # Filter by attack success\n",
        "      below_eps_filter = torch.max(torch.abs(x_batch_adv - x_batch_clean).view(x_batch_clean.shape[0], -1), dim=1)[0] < eps_linf\n",
        "      if torch.sum(below_eps_filter) != torch.sum(succ):      \n",
        "        # Shouldn't happen, but if it does then it should be investigated\n",
        "        print(f\"WARN: Actual attack success ({torch.sum(below_eps_filter).item()}) != reported attack success ({torch.sum(succ).item()})!\")\n",
        "\n",
        "      # Combine clean images with successfully attacked images and measure overall accuracy\n",
        "      x_batch_adv_below_eps = x_batch_clean.clone()\n",
        "      x_batch_adv_below_eps[below_eps_filter] = x_batch_adv[below_eps_filter]      \n",
        "      outputs = model(x_batch_adv_below_eps)\n",
        "      _, y_batch_pred = torch.max(outputs.data, 1)\n",
        "\n",
        "      n_total += x_batch_clean.shape[0]\n",
        "      n_robust_correct += (y_batch_pred == y_batch_gt).sum().item()\n",
        "      robust_acc = n_robust_correct / n_total\n",
        "\n",
        "      # This might take a long time, so display the running accuracy after every batch\n",
        "      progress_bar.set_description(f\"acc={robust_acc}\")\n",
        "\n",
        "  return robust_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EceA7YlFAYhB"
      },
      "source": [
        "## Running the attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0NfbuK32uWk",
        "outputId": "8976fa78-cced-4b30-887f-09287a37ea76"
      },
      "source": [
        "robust_acc = run_rays_attack(model_undefended, n_queries=rays_n_queries)\n",
        "print(f\"Undefended model robust accuracy: {robust_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running RayS attack with 1000 queries. This could take a while...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out of queries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc=0.73: 100%|██████████| 1/1 [22:32<00:00, 1352.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undefended model robust accuracy: 0.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-PbWt2kzGn3",
        "outputId": "36b89aef-9cc1-4cf2-cf20-eff2e2c4643a"
      },
      "source": [
        "robust_acc = run_rays_attack(model_defended, n_queries=rays_n_queries)\n",
        "print(f\"Defended model robust accuracy: {robust_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running RayS attack with 1000 queries. This could take a while...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out of queries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc=0.73: 100%|██████████| 1/1 [2:43:33<00:00, 9813.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defended model robust accuracy: 0.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts_eoCgju6Sf"
      },
      "source": [
        "- Robust accuracy is exactly the same, so the defense doesn't work against this attack. It does make evaluation very slow though. \n",
        "- Robust accuracy is significantly below the strongest result reported by Alfarra et al. (73% < 79%).\n",
        "- Robust accuracy further decreases when the attack is run for more iterations (we measured 67% against 10k iterations)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mRCut2jwPjk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}