{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEf66kxs5UHd"
   },
   "source": [
    "Evaluation of _Improving Model Robustness with Latent Distribution Locally and Globally_.\n",
    "\n",
    "To run this on a local runtime:\n",
    "```\n",
    "pip install jupyter_http_over_ws\n",
    "jupyter serverextension enable --py jupyter_http_over_ws\n",
    "pip install ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter notebook \\\n",
    "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
    "  --port=8888 \\\n",
    "  --NotebookApp.port_retries=0\n",
    "# Install python packages as you see fit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmEhulfHDN5Z"
   },
   "source": [
    "## Setup (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jUJ0PoelCfi0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ATLD-pytorch' already exists and is not an empty directory.\n",
      "Collecting git+https://github.com/fra31/auto-attack\n",
      "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-wmfwlg5a\n",
      "  Running command git clone -q https://github.com/fra31/auto-attack /tmp/pip-req-build-wmfwlg5a\n",
      "  Resolved https://github.com/fra31/auto-attack to commit b7f560b229145e6e90613cd3ce98cad6a94bd623\n",
      "Requirement already satisfied: foolbox<3 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied: setuptools in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from foolbox<3) (61.2.0)\n",
      "Requirement already satisfied: scipy in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from foolbox<3) (1.7.3)\n",
      "Requirement already satisfied: requests in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from foolbox<3) (2.25.1)\n",
      "Requirement already satisfied: GitPython in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from foolbox<3) (3.1.27)\n",
      "Requirement already satisfied: numpy in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from foolbox<3) (1.21.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from GitPython->foolbox<3) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from GitPython->foolbox<3) (4.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython->foolbox<3) (5.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from requests->foolbox<3) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from requests->foolbox<3) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from requests->foolbox<3) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from requests->foolbox<3) (2022.6.15)\n",
      "Requirement already satisfied: adversarial-robustness-toolbox in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: six in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (61.2.0)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.7.3)\n",
      "Requirement already satisfied: tqdm in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (4.56.2)\n",
      "Requirement already satisfied: numba>=0.53.1 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.55.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.21.6)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from numba>=0.53.1->adversarial-robustness-toolbox) (0.38.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/LitterQ/ATLD-pytorch\n",
    "!pip install git+https://github.com/fra31/auto-attack\n",
    "!pip install \"foolbox<3\"\n",
    "!pip install adversarial-robustness-toolbox\n",
    "import sys\n",
    "sys.path.insert(0,'ATLD-pytorch/cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LAjzfRRcC9ZA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18NOtz_z29iMKdv92xTkXhZLVeCvg0N_o\n",
      "To: /home/scratch/adversarialml/evaluating-adaptive-test-time-defenses/qian_2021/latest\n",
      "100%|████████████████████████████████████████| 365M/365M [00:55<00:00, 6.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 18NOtz_z29iMKdv92xTkXhZLVeCvg0N_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4mF3MQY5JoU"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ON80cyFp5I6c"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from models_new.wideresnet import *\n",
    "from models_new.dis import *\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmSKrxTuK8xj"
   },
   "source": [
    "## Build models and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8c6Au1Bwr3aZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 50  #@param {type: 'integer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JE36kLOwDiUs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "basic_net = WideResNet(depth=28, num_classes=10, widen_factor=10)\n",
    "basic_net = basic_net.to(device)\n",
    "discriminator = Discriminator_2(depth=28,num_classes=1,widen_factor=5).to(device)\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wBc10slELahm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iO254ZL3U6qK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded\n",
      "Discriminator loaded\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('latest', map_location=torch.device(device))\n",
    "basic_net_params = {}\n",
    "for k, v in checkpoint['net'].items():\n",
    "  if k.startswith('basic_net.'):\n",
    "    basic_net_params[k[len('basic_net.'):]] = v\n",
    "basic_net.load_state_dict(basic_net_params)\n",
    "print('Classifier loaded')\n",
    "\n",
    "disc_params = {}\n",
    "for k, v in checkpoint['net'].items():\n",
    "  if k.startswith('discriminator.'):\n",
    "    disc_params[k[len('discriminator.'):]] = v\n",
    "discriminator.load_state_dict(disc_params)\n",
    "print('Discriminator loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bLdtxwUgC1Ir"
   },
   "outputs": [],
   "source": [
    "basic_net.eval()\n",
    "discriminator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y2y5lzwx_B2n"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "def atld(classifier, discriminator, inputs, epsilon=8. / 255):\n",
    "  inputs = inputs * 2. - 1.\n",
    "  \n",
    "  # IMT\n",
    "  adversarial_criterion = nn.BCELoss()\n",
    "  valid = torch.Tensor(np.ones((inputs.size(0), 1)))\n",
    "  if device == 'cuda':\n",
    "    valid = valid.cuda()\n",
    "\n",
    "  with torch.enable_grad():\n",
    "    delta = Variable(torch.zeros_like(inputs), requires_grad=True)\n",
    "    if device == 'cuda':\n",
    "      delta = delta.cuda()\n",
    "    logits = classifier(inputs + delta)[0]\n",
    "    logits_reshaped = torch.reshape(logits, [inputs.size(0), 10, 1, 1])\n",
    "    logits_disc, _ = discriminator(logits_reshaped)\n",
    "    adv_loss = adversarial_criterion(logits_disc, valid)\n",
    "    adv_loss.backward(retain_graph=True)\n",
    "    grad = delta.grad.detach()\n",
    "\n",
    "  # Mask logits.\n",
    "  mask = torch.Tensor(np.ones((inputs.size(0), 1, 1, 1))).cuda()\n",
    "  for idx, v in enumerate(logits_disc):\n",
    "    if 0.3 < v < 0.7:\n",
    "      mask[idx] = 0.5\n",
    "  mask = mask.expand_as(inputs)\n",
    "  \n",
    "  inputs_repaired = inputs - epsilon * 2. * mask  * torch.sign(grad)\n",
    "  inputs_repaired = torch.clamp(inputs_repaired, -1., 1.)\n",
    "  outputs = classifier(inputs_repaired)[0]\n",
    "  return outputs, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5O6pM9yNQzv"
   },
   "source": [
    "# Accuracy\n",
    "\n",
    "In this section, we measure the nominal accuracy. The numbers mostly match the numbers reported in the paper. For ATLD+, there is a difference of 0.01-0.02% (which might be due to numerical errors). It's unclear where the randomness comes from.\n",
    "\n",
    "We expect 93.34% for ATLD- and 90.78% for ATLD+."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWb35R-HV7MC"
   },
   "source": [
    "## Vanilla (ATLD-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pCIhbb4oLb3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 9.792092561721802\n",
      "Accuracy: 93.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "basic_net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "def logits_fn(x):\n",
    "  return basic_net(x * 2. - 1.)[0]\n",
    "\n",
    "t = time.time()\n",
    "iterator = tqdm(testloader, ncols=0, leave=False)\n",
    "for batch_idx, (inputs, targets) in enumerate(iterator):\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "  outputs = logits_fn(inputs)\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "  total += targets.size(0)\n",
    "  correct += (predicted == targets).sum().item()\n",
    "print(f'Time: {time.time() - t}')\n",
    "acc = 100. * correct / total\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ph1yw6QS-ppJ"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.10.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2547/1719030220.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title FGSM (77.26%, expected 73.58%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProjectedGradientDescentPyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Project Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/attacks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReconstructionAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevasion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/attacks/evasion/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mproviding\u001b[0m \u001b[0mevasion\u001b[0m \u001b[0mattacks\u001b[0m \u001b[0munder\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdversarialPatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch_numpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdversarialPatchNumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch_tensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdversarialPatchTensorFlowV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/attacks/evasion/adversarial_patch/adversarial_patch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch_numpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdversarialPatchNumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch_tensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdversarialPatchTensorFlowV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdversarialPatchPyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/attacks/evasion/adversarial_patch/adversarial_patch_numpy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvasionAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevasion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minsert_transformed_patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeuralNetworkMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_and_transform_label_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/estimators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorFlowEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorFlowV2Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcertification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/estimators/certification/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandomized_smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mderandomized_smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/estimators/certification/derandomized_smoothing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderandomized_smoothing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderandomized_smoothing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeRandomizedSmoothingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderandomized_smoothing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchDeRandomizedSmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderandomized_smoothing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorFlowV2DeRandomizedSmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/art/estimators/certification/derandomized_smoothing/tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/lorenzp/.conda/envs/3.7_env/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "#@title FGSM (77.26%, expected 73.58%)\n",
    "\n",
    "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "class IdentityModule(nn.Module):\n",
    "  \"\"\"Simple Torch wrapper needed by the ART library.\"\"\"\n",
    "\n",
    "  def __init__(self, logits_fn):\n",
    "    super(IdentityModule, self).__init__()\n",
    "    self.logits_fn = logits_fn\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.logits_fn(x)\n",
    "\n",
    "\n",
    "def logits_fn(x):\n",
    "  return basic_net(x * 2. - 1.)[0]\n",
    "\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=IdentityModule(logits_fn),\n",
    "    clip_values=(0, 1),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10)\n",
    "\n",
    "attack = ProjectedGradientDescentPyTorch(estimator=classifier, eps=8/255, eps_step=2/255, max_iter=20, batch_size=batch_size)\n",
    "\n",
    "iterator = tqdm(testloader, ncols=0, leave=False)\n",
    "for batch_idx, (inputs, targets) in enumerate(iterator):\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "  x_adv = attack.generate(x=inputs.cpu().numpy())\n",
    "  outputs = logits_fn(torch.Tensor(x_adv).cuda())\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "  total += targets.size(0)\n",
    "  correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f'PGD20 accuracy\\t{correct * 100. / total:.2f}%')  # 77.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bMx3n8lV_Wr"
   },
   "source": [
    "## ATLD+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZMVhqL_MC1M"
   },
   "outputs": [],
   "source": [
    "def logits_fn(x):\n",
    "  return atld(basic_net, discriminator, x)[0]\n",
    "\n",
    "\n",
    "basic_net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "t = time.time()\n",
    "iterator = tqdm(testloader, ncols=0, leave=False)\n",
    "for batch_idx, (inputs, targets) in enumerate(iterator):\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "  outputs = logits_fn(inputs)\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "  total += targets.size(0)\n",
    "  correct += (predicted == targets).sum().item()\n",
    "print(f'Time: {time.time() - t}')\n",
    "acc = 100. * correct / total\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMWiQee9SKHi"
   },
   "source": [
    "# Robust accuracy (1 batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQODZ6XX_Uj9"
   },
   "outputs": [],
   "source": [
    "for inputs, targets in testloader:\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgQ_Crms73zv"
   },
   "source": [
    "## ATLD-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Hg6kJJRSLwQ"
   },
   "outputs": [],
   "source": [
    "def logits_fn(x):\n",
    "  return basic_net(x * 2. - 1.)[0]\n",
    "\n",
    "# Nominal accuracy.\n",
    "outputs = logits_fn(inputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total = targets.size(0)\n",
    "correct = (predicted == targets).sum().item()\n",
    "print(f'nominal accuracy\\t{correct * 100. / total:.2f}%')\n",
    "\n",
    "from autoattack import AutoAttack\n",
    "adversary = AutoAttack(logits_fn, norm='Linf', eps=8. / 255, verbose=True)\n",
    "adversary.attacks_to_run = ['apgd-ce', 'apgd-t']\n",
    "adv_autoattack, adv_labels = adversary.run_standard_evaluation(inputs, targets, bs=inputs.shape[0], return_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Moc_bVNU77u5"
   },
   "source": [
    "## ATLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwM_7TMfwpd8"
   },
   "outputs": [],
   "source": [
    "def logits_fn(x):\n",
    "  return atld(basic_net, discriminator, x)[0]\n",
    "\n",
    "# Nominal accuracy.\n",
    "outputs = logits_fn(inputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total = targets.size(0)\n",
    "correct = (predicted == targets).sum().item()\n",
    "print(f'nominal accuracy\\t{correct * 100. / total:.2f}%')\n",
    "\n",
    "from autoattack import AutoAttack\n",
    "adversary = AutoAttack(logits_fn, norm='Linf', eps=8. / 255, verbose=True)\n",
    "adversary.attacks_to_run = ['apgd-ce', 'apgd-t']\n",
    "adv_autoattack, adv_labels_atld = adversary.run_standard_evaluation(inputs, targets, bs=inputs.shape[0], return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TmEhulfHDN5Z"
   ],
   "name": "qian_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-3.7_env]",
   "language": "python",
   "name": "conda-env-.conda-3.7_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
