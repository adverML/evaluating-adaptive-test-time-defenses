{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of _Improving Model Robustness with Latent Distribution Locally and Globally_.\n",
        "\n",
        "To run this on a local runtime:\n",
        "```\n",
        "pip install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "pip install ipywidgets\n",
        "jupyter nbextension enable --py widgetsnbextension\n",
        "jupyter notebook \\\n",
        "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
        "  --port=8888 \\\n",
        "  --NotebookApp.port_retries=0\n",
        "# Install python packages as you see fit\n",
        "```"
      ],
      "metadata": {
        "id": "hEf66kxs5UHd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmEhulfHDN5Z"
      },
      "source": [
        "## Setup (run once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUJ0PoelCfi0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/LitterQ/ATLD-pytorch\n",
        "!pip install git+https://github.com/fra31/auto-attack\n",
        "!pip install \"foolbox<3\"\n",
        "!pip install adversarial-robustness-toolbox\n",
        "import sys\n",
        "sys.path.insert(0,'ATLD-pytorch/cifar10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAjzfRRcC9ZA"
      },
      "outputs": [],
      "source": [
        "!gdown --id 18NOtz_z29iMKdv92xTkXhZLVeCvg0N_o"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "s4mF3MQY5JoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "from models_new.wideresnet import *\n",
        "from models_new.dis import *\n",
        "import utils"
      ],
      "metadata": {
        "id": "ON80cyFp5I6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSKrxTuK8xj"
      },
      "source": [
        "## Build models and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c6Au1Bwr3aZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 50  #@param {type: 'integer'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE36kLOwDiUs"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "basic_net = WideResNet(depth=28, num_classes=10, widen_factor=10)\n",
        "basic_net = basic_net.to(device)\n",
        "discriminator = Discriminator_2(depth=28,num_classes=1,widen_factor=5).to(device)\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBc10slELahm"
      },
      "outputs": [],
      "source": [
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO254ZL3U6qK"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('latest', map_location=torch.device(device))\n",
        "basic_net_params = {}\n",
        "for k, v in checkpoint['net'].items():\n",
        "  if k.startswith('basic_net.'):\n",
        "    basic_net_params[k[len('basic_net.'):]] = v\n",
        "basic_net.load_state_dict(basic_net_params)\n",
        "print('Classifier loaded')\n",
        "\n",
        "disc_params = {}\n",
        "for k, v in checkpoint['net'].items():\n",
        "  if k.startswith('discriminator.'):\n",
        "    disc_params[k[len('discriminator.'):]] = v\n",
        "discriminator.load_state_dict(disc_params)\n",
        "print('Discriminator loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLdtxwUgC1Ir"
      },
      "outputs": [],
      "source": [
        "basic_net.eval()\n",
        "discriminator.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2y5lzwx_B2n"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "def atld(classifier, discriminator, inputs, epsilon=8. / 255):\n",
        "  inputs = inputs * 2. - 1.\n",
        "  \n",
        "  # IMT\n",
        "  adversarial_criterion = nn.BCELoss()\n",
        "  valid = torch.Tensor(np.ones((inputs.size(0), 1)))\n",
        "  if device == 'cuda':\n",
        "    valid = valid.cuda()\n",
        "\n",
        "  with torch.enable_grad():\n",
        "    delta = Variable(torch.zeros_like(inputs), requires_grad=True)\n",
        "    if device == 'cuda':\n",
        "      delta = delta.cuda()\n",
        "    logits = classifier(inputs + delta)[0]\n",
        "    logits_reshaped = torch.reshape(logits, [inputs.size(0), 10, 1, 1])\n",
        "    logits_disc, _ = discriminator(logits_reshaped)\n",
        "    adv_loss = adversarial_criterion(logits_disc, valid)\n",
        "    adv_loss.backward(retain_graph=True)\n",
        "    grad = delta.grad.detach()\n",
        "\n",
        "  # Mask logits.\n",
        "  mask = torch.Tensor(np.ones((inputs.size(0), 1, 1, 1))).cuda()\n",
        "  for idx, v in enumerate(logits_disc):\n",
        "    if 0.3 < v < 0.7:\n",
        "      mask[idx] = 0.5\n",
        "  mask = mask.expand_as(inputs)\n",
        "  \n",
        "  inputs_repaired = inputs - epsilon * 2. * mask  * torch.sign(grad)\n",
        "  inputs_repaired = torch.clamp(inputs_repaired, -1., 1.)\n",
        "  outputs = classifier(inputs_repaired)[0]\n",
        "  return outputs, None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5O6pM9yNQzv"
      },
      "source": [
        "# Accuracy\n",
        "\n",
        "In this section, we measure the nominal accuracy. The numbers mostly match the numbers reported in the paper. For ATLD+, there is a difference of 0.01-0.02% (which might be due to numerical errors). It's unclear where the randomness comes from.\n",
        "\n",
        "We expect 93.34% for ATLD- and 90.78% for ATLD+."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWb35R-HV7MC"
      },
      "source": [
        "## Vanilla (ATLD-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCIhbb4oLb3a"
      },
      "outputs": [],
      "source": [
        "basic_net.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "def logits_fn(x):\n",
        "  return basic_net(x * 2. - 1.)[0]\n",
        "\n",
        "t = time.time()\n",
        "iterator = tqdm(testloader, ncols=0, leave=False)\n",
        "for batch_idx, (inputs, targets) in enumerate(iterator):\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "  outputs = logits_fn(inputs)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  total += targets.size(0)\n",
        "  correct += (predicted == targets).sum().item()\n",
        "print(f'Time: {time.time() - t}')\n",
        "acc = 100. * correct / total\n",
        "print('Accuracy:', acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FGSM (77.26%, expected 73.58%)\n",
        "\n",
        "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "\n",
        "class IdentityModule(nn.Module):\n",
        "  \"\"\"Simple Torch wrapper needed by the ART library.\"\"\"\n",
        "\n",
        "  def __init__(self, logits_fn):\n",
        "    super(IdentityModule, self).__init__()\n",
        "    self.logits_fn = logits_fn\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.logits_fn(x)\n",
        "\n",
        "\n",
        "def logits_fn(x):\n",
        "  return basic_net(x * 2. - 1.)[0]\n",
        "\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=IdentityModule(logits_fn),\n",
        "    clip_values=(0, 1),\n",
        "    loss=nn.CrossEntropyLoss(),\n",
        "    input_shape=(3, 32, 32),\n",
        "    nb_classes=10)\n",
        "\n",
        "attack = ProjectedGradientDescentPyTorch(estimator=classifier, eps=8/255, eps_step=2/255, max_iter=20, batch_size=batch_size)\n",
        "\n",
        "iterator = tqdm(testloader, ncols=0, leave=False)\n",
        "for batch_idx, (inputs, targets) in enumerate(iterator):\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "  x_adv = attack.generate(x=inputs.cpu().numpy())\n",
        "  outputs = logits_fn(torch.Tensor(x_adv).cuda())\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  total += targets.size(0)\n",
        "  correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(f'PGD20 accuracy\\t{correct * 100. / total:.2f}%')  # 77.26%"
      ],
      "metadata": {
        "id": "Ph1yw6QS-ppJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bMx3n8lV_Wr"
      },
      "source": [
        "## ATLD+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZMVhqL_MC1M"
      },
      "outputs": [],
      "source": [
        "def logits_fn(x):\n",
        "  return atld(basic_net, discriminator, x)[0]\n",
        "\n",
        "\n",
        "basic_net.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "t = time.time()\n",
        "iterator = tqdm(testloader, ncols=0, leave=False)\n",
        "for batch_idx, (inputs, targets) in enumerate(iterator):\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "  outputs = logits_fn(inputs)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  total += targets.size(0)\n",
        "  correct += (predicted == targets).sum().item()\n",
        "print(f'Time: {time.time() - t}')\n",
        "acc = 100. * correct / total\n",
        "print('Accuracy:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMWiQee9SKHi"
      },
      "source": [
        "# Robust accuracy (1 batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQODZ6XX_Uj9"
      },
      "outputs": [],
      "source": [
        "for inputs, targets in testloader:\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgQ_Crms73zv"
      },
      "source": [
        "## ATLD-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Hg6kJJRSLwQ"
      },
      "outputs": [],
      "source": [
        "def logits_fn(x):\n",
        "  return basic_net(x * 2. - 1.)[0]\n",
        "\n",
        "# Nominal accuracy.\n",
        "outputs = logits_fn(inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "total = targets.size(0)\n",
        "correct = (predicted == targets).sum().item()\n",
        "print(f'nominal accuracy\\t{correct * 100. / total:.2f}%')\n",
        "\n",
        "from autoattack import AutoAttack\n",
        "adversary = AutoAttack(logits_fn, norm='Linf', eps=8. / 255, verbose=True)\n",
        "adversary.attacks_to_run = ['apgd-ce', 'apgd-t']\n",
        "adv_autoattack, adv_labels = adversary.run_standard_evaluation(inputs, targets, bs=inputs.shape[0], return_labels=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Moc_bVNU77u5"
      },
      "source": [
        "## ATLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwM_7TMfwpd8"
      },
      "outputs": [],
      "source": [
        "def logits_fn(x):\n",
        "  return atld(basic_net, discriminator, x)[0]\n",
        "\n",
        "# Nominal accuracy.\n",
        "outputs = logits_fn(inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "total = targets.size(0)\n",
        "correct = (predicted == targets).sum().item()\n",
        "print(f'nominal accuracy\\t{correct * 100. / total:.2f}%')\n",
        "\n",
        "from autoattack import AutoAttack\n",
        "adversary = AutoAttack(logits_fn, norm='Linf', eps=8. / 255, verbose=True)\n",
        "adversary.attacks_to_run = ['apgd-ce', 'apgd-t']\n",
        "adv_autoattack, adv_labels_atld = adversary.run_standard_evaluation(inputs, targets, bs=inputs.shape[0], return_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WYw1qacO-GxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TmEhulfHDN5Z"
      ],
      "name": "qian_2021.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}