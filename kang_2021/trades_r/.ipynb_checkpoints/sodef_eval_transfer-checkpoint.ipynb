{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "Use activation of ReLU\n",
      "Sequential(\n",
      "  (0): WideResNet_save(\n",
      "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (block1): NetworkBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (sub_block1): NetworkBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block2): NetworkBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block3): NetworkBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (fc1): fcs(\n",
      "      (merge_net): Sequential(\n",
      "        (0): Linear(in_features=640, out_features=2048, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "        (3): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): ODEBlock(\n",
      "    (odefunc): ODEfunc_mlp(\n",
      "      (fc1): ConcatFC(\n",
      "        (_layer): Linear(in_features=64, out_features=256, bias=True)\n",
      "      )\n",
      "      (fc2): ConcatFC(\n",
      "        (_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (fc3): ConcatFC(\n",
      "        (_layer): Linear(in_features=256, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): MLP_OUT_Linear(\n",
      "    (fc0): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "run_standard_evaluation_individual Linf\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "Use activation of ReLU\n",
      "setting parameters for standard version\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square\n",
      "initial accuracy: 85.74%\n",
      "apgd-ce - 1/1 - 143 out of 439 successfully perturbed\n",
      "robust accuracy after APGD-CE: 57.81% (total time 80.2 s)\n",
      "apgd-t - 1/1 - 11 out of 296 successfully perturbed\n",
      "robust accuracy after APGD-T: 55.66% (total time 601.3 s)\n",
      "fab-t - 1/1 - 0 out of 285 successfully perturbed\n",
      "robust accuracy after FAB-T: 55.66% (total time 1279.2 s)\n",
      "square - 1/1 - 0 out of 285 successfully perturbed\n",
      "robust accuracy after SQUARE: 55.66% (total time 2131.5 s)\n",
      "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 55.66%\n",
      "transfer attack acc using adv examples generated from original pretrained model without sodef:  0.638671875\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import logging\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from preactresnet import PreActResNet18\n",
    "from wideresnet import WideResNet,WideResNet1,WideResNet_save\n",
    "from utils_plus import (upper_limit, lower_limit, std, clamp, get_loaders,\n",
    "    attack_pgd, evaluate_pgd, evaluate_standard, normalize)\n",
    "from autoattack import AutoAttack\n",
    "import torch.utils.data as data\n",
    "device = torch.device('cuda:0') \n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "endtime = 5\n",
    "\n",
    "fc_dim = 64\n",
    "act = torch.sin \n",
    "f_coeffi = -1\n",
    "layernum = 0\n",
    "tol = 1e-3\n",
    "\n",
    "\n",
    "saved_temp = torch.load('./EXP/nips_model/full.pth')\n",
    "statedic_temp = saved_temp['state_dict']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch-size', default=128, type=int)\n",
    "    parser.add_argument('--data-dir', default='../cifar-data', type=str)\n",
    "    parser.add_argument('--epsilon', default=8, type=int)\n",
    "    parser.add_argument('--out-dir', default='train_fgsm_output', type=str, help='Output directory')\n",
    "    parser.add_argument('--seed', default=0, type=int, help='Random seed')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def one_hot(x, K):\n",
    "    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n",
    "\n",
    "\n",
    "def accuracy(model, dataset_loader):\n",
    "    total_correct = 0\n",
    "    for x, y in dataset_loader:\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), 10)\n",
    "\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "        predicted_class = np.argmax(model(x)[0].cpu().detach().numpy(), axis=1)\n",
    "        total_correct += np.sum(predicted_class == target_class)\n",
    "    return total_correct / len(dataset_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "def makedirs(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConcatFC(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ConcatFC, self).__init__()\n",
    "        self._layer = nn.Linear(dim_in, dim_out)\n",
    "    def forward(self, t, x):\n",
    "        return self._layer(x)\n",
    "\n",
    "\n",
    "    \n",
    "class ODEfunc_mlp(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(ODEfunc_mlp, self).__init__()\n",
    "        self.fc1 = ConcatFC(64, 256)\n",
    "        self.act1 = act\n",
    "        self.fc2 = ConcatFC(256, 256)\n",
    "        self.act2 = act\n",
    "        self.fc3 = ConcatFC(256, 64)\n",
    "        self.act3 = act\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = f_coeffi*self.fc1(t, x)\n",
    "        out = self.act1(out)\n",
    "        out = f_coeffi*self.fc2(t, out)\n",
    "        out = self.act2(out)\n",
    "        out = f_coeffi*self.fc3(t, out)\n",
    "        out = self.act3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n",
    "class ODEBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, odefunc):\n",
    "        super(ODEBlock, self).__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.integration_time = torch.tensor([0, endtime]).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.integration_time = self.integration_time.type_as(x)\n",
    "        out = odeint(self.odefunc, x, self.integration_time, rtol=tol, atol=tol)\n",
    "        return out[1]\n",
    "\n",
    "    @property\n",
    "    def nfe(self):\n",
    "        return self.odefunc.nfe\n",
    "\n",
    "    @nfe.setter\n",
    "    def nfe(self, value):\n",
    "        self.odefunc.nfe = value\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)\n",
    "\n",
    "    \n",
    "class MLP_OUT_Linear(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP_OUT_Linear, self).__init__()\n",
    "        self.fc0 = nn.Linear(fc_dim, 10)\n",
    "    def forward(self, input_):\n",
    "#         h1 = F.relu(self.fc0(input_))\n",
    "        h1 = self.fc0(input_)\n",
    "        return h1\n",
    "\n",
    "\n",
    "def inf_generator(iterable):\n",
    "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
    "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
    "    \"\"\"\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch-size', default=128, type=int)\n",
    "    parser.add_argument('--data-dir', default='../cifar-data', type=str)\n",
    "    parser.add_argument('--epsilon', default=8, type=int)\n",
    "    parser.add_argument('--out-dir', default='train_fgsm_output', type=str, help='Output directory')\n",
    "    parser.add_argument('--seed', default=0, type=int, help='Random seed')\n",
    "#     return parser.parse_args()\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "def one_hot(x, K):\n",
    "    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n",
    "\n",
    "\n",
    "def accuracy(model, dataset_loader):\n",
    "    total_correct = 0\n",
    "    for x, y in dataset_loader:\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), 10)\n",
    "\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n",
    "        total_correct += np.sum(predicted_class == target_class)\n",
    "    return total_correct / len(dataset_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "def makedirs(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "args = get_args()\n",
    "nepochs = 100\n",
    "batches_per_epoch = 128\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = WideResNet_save(fc_dim, 34, 10, widen_factor=10, dropRate=0.0)\n",
    "odefunc = ODEfunc_mlp(0)\n",
    "feature_layers = [ODEBlock(odefunc)] \n",
    "fc_layers = [MLP_OUT_Linear()]\n",
    "\n",
    "\n",
    "model = nn.Sequential(model, *feature_layers, *fc_layers).to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(statedic_temp)\n",
    "\n",
    "print(model)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "train_loader, test_loader, train_loader__, test_dataset = get_loaders(args.data_dir, args.batch_size)\n",
    "class mnist_samples(data.Dataset):\n",
    "    def __init__(self, dataset, leng, iid):\n",
    "        self.dataset = dataset\n",
    "        self.len = leng\n",
    "        self.iid = iid\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.dataset[idx+self.len*self.iid]\n",
    "        return x,y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################### load original pretrained model and generate aa attack adv samples ############            return self.len\n",
    "\n",
    "    # x_test, y_test = load_cifar100(n_examples=100)\n",
    "samplenum = 512\n",
    "test_samples = mnist_samples(test_dataset,samplenum,1)\n",
    "test_loader_samples = data.DataLoader(test_samples, batch_size=100, shuffle=False, num_workers=2, drop_last=False)\n",
    "#     x_test, y_test = _load_dataset(test_samples,300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('run_standard_evaluation_individual', 'Linf')\n",
    "# print('run_standard_evaluation_individual', 'L2')\n",
    "\n",
    "\n",
    "#     test_loader = test_loader\n",
    "test_loader = test_loader_samples\n",
    "\n",
    "l = [x for (x, y) in test_loader]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in test_loader]\n",
    "y_test = torch.cat(l, 0)\n",
    "\n",
    "\n",
    "\n",
    "best_state_dict = torch.load('./EXP/pre_train_model/wide10_trades_eps8_tricks.pt')\n",
    "# Evaluation\n",
    "model_test = WideResNet(34, 10, widen_factor=10, dropRate=0.0).cuda()\n",
    "if 'state_dict' in best_state_dict.keys():\n",
    "    model_test.load_state_dict(best_state_dict['state_dict'])\n",
    "else:\n",
    "    model_test.load_state_dict(best_state_dict)\n",
    "model_test.float()\n",
    "model_test.eval()\n",
    "\n",
    "\n",
    "\n",
    "epsilon = 8 / 255.\n",
    "adversary = AutoAttack(model_test, norm='Linf', eps=epsilon, version='standard')\n",
    "\n",
    "#     epsilon = 0.5\n",
    "#     adversary = AutoAttack(new_model, norm='L2', eps=epsilon, version='standard')\n",
    "\n",
    "\n",
    "# adversary.attacks_to_run = ['apgd-ce', 'apgd-t']\n",
    "\n",
    "X_adv = adversary.run_standard_evaluation(x_test, y_test, bs=512)\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "total_correct = 0\n",
    "x = X_adv.to(device)\n",
    "\n",
    "target_class = y_test\n",
    "predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n",
    "\n",
    "\n",
    "# print(target_class)\n",
    "# print(\"==========\")\n",
    "# print(predicted_class)\n",
    "\n",
    "print(\"transfer attack acc using adv examples generated from original pretrained model without sodef: \", sum(target_class.numpy()== predicted_class)/samplenum)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
